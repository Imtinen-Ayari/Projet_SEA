{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be9e14ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title of https://www.wikipedia.org: Wikipedia\n",
      "Title of https://www.youtube.com: YouTube\n",
      "Title of https://www.reddit.com: Reddit - Dive into anything\n",
      "Total execution time: 2.50 seconds\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from queue import Queue\n",
    "import time\n",
    "import csv\n",
    "import urllib.robotparser\n",
    "\n",
    "NUM_THREADS = 5\n",
    "url_queue = Queue()\n",
    "urls_to_crawl = [\n",
    "    'https://www.youtube.com',\n",
    "    'https://www.wikipedia.org',\n",
    "    'https://www.reddit.com'\n",
    "]\n",
    "\n",
    "output_file = 'crawl_results.csv'\n",
    "\n",
    "# Initialisation du fichier CSV\n",
    "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['URL', 'Title'])\n",
    "\n",
    "def can_fetch(url):\n",
    "    rp = urllib.robotparser.RobotFileParser()\n",
    "    rp.set_url(url + '/robots.txt')\n",
    "    rp.read()\n",
    "    return rp.can_fetch('*', url)\n",
    "\n",
    "def crawl(url):\n",
    "    if not can_fetch(url):\n",
    "        print(f'Crawling disallowed by robots.txt for {url}')\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        title = soup.title.string if soup.title else 'No title'\n",
    "        with threading.Lock():\n",
    "            with open(output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([url, title])\n",
    "        print(f'Title of {url}: {title}')\n",
    "    except requests.RequestException as e:\n",
    "        print(f'Error crawling {url}: {e}')\n",
    "\n",
    "def worker():\n",
    "    while True:\n",
    "        url = url_queue.get()\n",
    "        if url is None:\n",
    "            break\n",
    "        crawl(url)\n",
    "        time.sleep(1)  # Pause d'une seconde entre les requêtes\n",
    "        url_queue.task_done()\n",
    "\n",
    "# Fonction pour mesurer le temps d'exécution\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "\n",
    "    threads = []\n",
    "    for _ in range(NUM_THREADS):\n",
    "        t = threading.Thread(target=worker)\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "\n",
    "    for url in urls_to_crawl:\n",
    "        url_queue.put(url)\n",
    "\n",
    "    url_queue.join()\n",
    "\n",
    "    for _ in range(NUM_THREADS):\n",
    "        url_queue.put(None)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'Total execution time: {elapsed_time:.2f} seconds')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a49b82a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title of https://www.wikipedia.org: Wikipedia\n",
      "Title of https://www.reddit.com: Reddit - Dive into anything\n",
      "Title of https://en.wikipedia.org/wiki/List_of_Wikipedia_mobile_applications: List of Wikipedia mobile applications - Wikipedia\n",
      "Crawling disallowed by robots.txt for https://creativecommons.org/licenses/by-sa/4.0/\n",
      "Title of https://meta.wikimedia.org/wiki/Special:MyLanguage/List_of_Wikipedias: List of Wikipedias - Meta\n",
      "Title of https://meta.wikimedia.org/wiki/Privacy_policy: Privacy policy - Meta\n",
      "Title of https://meta.wikimedia.org/wiki/Terms_of_use: Terms of use - Meta\n",
      "Title of https://donate.wikimedia.org/?utm_medium=portal&utm_campaign=portalFooter&utm_source=portalFooter: Make your donation now - Wikimedia Foundation\n",
      "Title of https://play.google.com/store/apps/details?id=org.wikipedia&referrer=utm_source%3Dportal%26utm_medium%3Dbutton%26anid%3Dadmob: Wikipedia - Apps on Google Play\n",
      "Title of https://accounts.reddit.com/adsregister?utm_source=web3x_consumer&utm_name=user_menu_cta: \n",
      "            \n",
      "                Sign Up for Reddit Ads\n",
      "            \n",
      "        \n",
      "Title of https://play.google.com/store/apps/details?id=com.reddit.frontpage: Reddit - Apps on Google Play\n",
      "Title of https://www.reddit.com/login/: Reddit - Dive into anything\n",
      "Title of https://apps.apple.com/US/app/id1064216828: \n",
      "      âReddit on the AppÂ Store\n",
      "    \n",
      "Crawling disallowed by robots.txt for https://apnews.com/projects/trump-investigations-civil-criminal-tracker/\n",
      "Title of https://en.wikipedia.org/wiki/File:Donald-J.-Trump-Indictment.pdf: File:Donald-J.-Trump-Indictment.pdf - Wikipedia\n",
      "Title of https://itunes.apple.com/app/apple-store/id324715238?pt=208305&ct=portal&mt=8: \n",
      "      âWikipedia on the AppÂ Store\n",
      "    \n",
      "Title of https://www.nysenate.gov/legislation/laws/PEN/175.10: NYS Open Legislation | NYSenate.gov\n",
      "Title of https://www.msnbc.com/deadline-white-house/deadline-legal-blog/donald-trump-guilty-hush-money-trial-rcna154272: Trump convicted: First former U.S. president found guilty of falsifying business records\n",
      "Title of https://www.usatoday.com/story/news/politics/2024/05/30/donald-trump-verdict-criminal-hush-money-trial/73891042007/: Trump guilty verdict recap: What happens now? Can he still run?\n",
      "Title of https://www.nbcnews.com/politics/donald-trump/donald-trump-verdict-hush-money-trial-rcna152492: Donald Trump found guilty in historic New York hush money case\n",
      "Title of https://nypost.com/2024/05/30/us-news/donald-trump-convicted-of-illegally-fudging-business-records-in-historic-manhattan-hush-money-case/: Donald Trump convicted of illegally fudging business records in historic Manhattan hush money case\n",
      "Title of https://www.nbcnews.com/news/amp/rcna152492: Donald Trump found guilty in historic New York hush money case\n",
      "Crawling disallowed by robots.txt for https://www.reuters.com/world/us/trump-hush-money-trial-decision-is-jurys-hands-2024-05-30/?utm_source=reddit.com\n",
      "Title of https://www.nbcnewyork.com/news/local/trump-verdict-stormy-daniels-trial/5448835/: Trump verdict reached: jury finds former president guilty on all counts – NBC New York\n",
      "Title of https://www.cnbc.com/2024/05/30/trump-guilty-crime-felony-what-happens-next.html?__source=iosappshare%7Ccom.apple.UIKit.activity.CopyToPasteboard: Trump has been convicted. Here's what happens next\n",
      "Crawling disallowed by robots.txt for https://thehill.com/regulation/court-battles/4682289-trump-hush-money-trial-verdict/\n",
      "Crawling disallowed by robots.txt for https://apnews.com/article/85558c6d08efb434d05b694364470aa0\n",
      "Title of https://edition.cnn.com/2024/05/30/politics/donald-trump-hush-money-trial-verdict/index.html: Trump found guilty in hush money trial | CNN Politics\n",
      "Title of https://abc7.com/live-updates/trump-trial-live-updates-verdict-reached-in-historic-hush-money-payment-case/14890411/: Trump trial live updates: Trump found guilty on all 34 counts - ABC7 Los Angeles\n",
      "Title of https://www.independent.co.uk/news/world/americas/us-politics/donald-trump-guilty-verdict-hush-money-trial-b2551318.html: Trump found guilty, becomes first criminally convicted US president after hush money trial | The Independent\n",
      "Title of https://www.rollingstone.com/politics/politics-news/donald-trump-found-guilty-hush-money-trial-1235029425/: Donald Trump Found Guilty in Hush-Money Trial\n",
      "Crawling disallowed by robots.txt for https://www.reuters.com/legal/jurors-begin-second-day-deliberations-trump-hush-money-trial-2024-05-30/\n",
      "Crawling disallowed by robots.txt for https://apnews.com/article/7dfc763f996cc5e9ddde47eca6e7fd37\n",
      "Title of https://www.npr.org/2024/05/30/nx-s1-4977352/trump-trial-verdict: Donald Trump is found guilty in hush money case : NPR\n",
      "Crawling disallowed by robots.txt for https://apnews.com/article/trump-trial-deliberations-jury-testimony-verdict-85558c6d08efb434d05b694364470aa0\n",
      "Title of https://www.cnbc.com/amp/2024/05/30/trump-trial-verdict-hush-money.html: Trump guilty in hush money trial in New York\n",
      "Title of https://www.cbsnews.com/news/donald-trump-convicted-prison-sentence-new-york-criminal-trial/: \n",
      "    Is Trump going to prison? What to know about the possible sentence after his conviction - CBS News\n",
      "Title of https://www.foxnews.com/politics/what-happens-trump-convicted-legal-experts-break-down: What happens after Trump's conviction? Legal experts break it down | Fox News\n",
      "Crawling disallowed by robots.txt for https://www.politico.com/news/2024/05/30/donald-trump-guilty-hush-money-trial-00160460\n",
      "Title of https://www.cnbc.com/2024/05/30/trump-trial-verdict-hush-money.html: Trump guilty in hush money trial in New York\n",
      "Crawling disallowed by robots.txt for https://www.newsweek.com/live-updates-jury-begins-day-2-deliberations-trump-hush-money-trial-1906289\n",
      "Crawling disallowed by robots.txt for https://apnews.com/live/trump-trial-jury-updates-day-2\n",
      "Title of https://www.local10.com/news/local/2024/05/30/judge-rereads-jury-instructions-in-trump-hush-money-trial-as-deliberations-set-to-resume/: Jury finds Trump guilty on all 34 counts; ex-president says he is a ‘very innocent man’\n",
      "Title of https://www.theguardian.com/us-news/article/2024/may/30/trump-trial-hush-money-verdict?CMP=Share_iOSApp_Other: Donald Trump found guilty of hush-money plot to influence 2016 election | Donald Trump trials | The Guardian\n",
      "Crawling disallowed by robots.txt for https://www.vanityfair.com/news/story/donald-trump-trial-verdict\n",
      "Crawling disallowed by robots.txt for https://www.wsj.com/us-news/law/donald-trump-convicted-87a4e465?mod=breakingnews\n",
      "Title of https://news.sky.com/story/amp/donald-trump-found-guilty-in-hush-money-case-becoming-first-ex-president-to-be-criminally-convicted-13144347: Donald Trump found guilty in hush money case - becoming first ex-president to be criminally convicted | US News | Sky News\n",
      "Title of https://abc7ny.com/post/trump-hush-money-trial-live-updates-closing-arguments-guilty-verdict/14879248/: Trump Hush Money Trial Live Updates: Former president set to address public from Trump Tower one day after conviction - ABC7 New York\n",
      "Title of https://www.huffpost.com/entry/trump-guilty-hush-money-trial_n_664f78b1e4b01123ffe493fd?72p: Donald Trump Found Guilty In Historic Hush Money Trial | HuffPost Latest News\n",
      "Title of https://www.washingtonpost.com/politics/2024/05/30/trump-guilty-verdict-hush-money-trial/: Donald Trump found guilty on all counts in New York hush money trial - The Washington Post\n",
      "Total execution time: 34.53 seconds\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from queue import Queue\n",
    "import time\n",
    "import csv\n",
    "import urllib.robotparser\n",
    "\n",
    "NUM_THREADS = 5\n",
    "MAX_URLS = 50  # Limite le nombre d'URLs à crawler\n",
    "url_queue = Queue()\n",
    "visited_urls = set()\n",
    "initial_urls = [\n",
    "    'https://www.wikipedia.org',\n",
    "    'https://www.reddit.com',\n",
    "    'https://www.youtube.com'\n",
    "]\n",
    "\n",
    "output_file = 'crawl_results.csv'\n",
    "\n",
    "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['URL', 'Title'])\n",
    "\n",
    "def can_fetch(url):\n",
    "    try:\n",
    "        rp = urllib.robotparser.RobotFileParser()\n",
    "        rp.set_url(url + '/robots.txt')\n",
    "        rp.read()\n",
    "        return rp.can_fetch('*', url)\n",
    "    except Exception as e:\n",
    "        print(f'Error reading robots.txt for {url}: {e}')\n",
    "        return False\n",
    "\n",
    "def crawl(url):\n",
    "    if not can_fetch(url):\n",
    "        print(f'Crawling disallowed by robots.txt for {url}')\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        title = soup.title.string if soup.title else 'No title'\n",
    "        with threading.Lock():\n",
    "            with open(output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([url, title])\n",
    "        print(f'Title of {url}: {title}')\n",
    "        \n",
    "        # Find and queue internal links\n",
    "        for link in soup.find_all('a', href=True):\n",
    "            href = link['href']\n",
    "            if href.startswith('http'):\n",
    "                if href not in visited_urls and len(visited_urls) < MAX_URLS:\n",
    "                    visited_urls.add(href)\n",
    "                    url_queue.put(href)\n",
    "    except requests.RequestException as e:\n",
    "        print(f'Error crawling {url}: {e}')\n",
    "\n",
    "def worker():\n",
    "    while True:\n",
    "        url = url_queue.get()\n",
    "        if url is None:\n",
    "            break\n",
    "        crawl(url)\n",
    "        # Reduce delay between requests to 0.5 to 1 second\n",
    "        time.sleep(0.5)\n",
    "        url_queue.task_done()\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "\n",
    "    threads = []\n",
    "    for _ in range(NUM_THREADS):\n",
    "        t = threading.Thread(target=worker)\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "\n",
    "    for url in initial_urls:\n",
    "        url_queue.put(url)\n",
    "        visited_urls.add(url)\n",
    "\n",
    "    url_queue.join()\n",
    "\n",
    "    for _ in range(NUM_THREADS):\n",
    "        url_queue.put(None)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'Total execution time: {elapsed_time:.2f} seconds')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc16acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
